# Readle Chatbot API - Restructured

A well-organized, modular FastAPI application for the Readle dyslexia support chatbot.

## ğŸ“ Project Structure

```
chatbot/
â”œâ”€â”€ __init__.py                 # Package initialization
â”œâ”€â”€ main.py                     # Main FastAPI application
â”œâ”€â”€ core/                       # Core configuration
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ config.py              # Settings and configuration
â”œâ”€â”€ api/                        # API routes
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ chat.py                # Chat endpoints
â”‚   â”œâ”€â”€ rag.py                 # RAG management endpoints
â”‚   â””â”€â”€ system.py              # Health and utility endpoints
â”œâ”€â”€ services/                   # Business logic services
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ memory.py              # Chat session management
â”‚   â”œâ”€â”€ rag.py                 # RAG system and document processing
â”‚   â””â”€â”€ llm.py                 # LLM service (Groq integration)
â”œâ”€â”€ models/                     # Data models
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ schemas.py             # Pydantic models
â””â”€â”€ utils/                      # Utility functions
    â”œâ”€â”€ __init__.py
    â””â”€â”€ text_processing.py     # Text analysis and processing
```

## ğŸš€ Quick Start

### Option 1: Using the new startup script
```bash
python run_chatbot.py
```

### Option 2: Using uvicorn directly
```bash
uvicorn chatbot.main:app --host 0.0.0.0 --port 8000 --reload
```

### Option 3: Using the legacy script (still works)
```bash
python chatbot_api.py
```

## ğŸ”§ Configuration

All configuration is managed in `chatbot/core/config.py`. Environment variables are loaded automatically from `.env`:

```env
# Required
GROQ_API_KEY=your_groq_api_key

# Optional (with defaults)
PORT=8000
RAG_THRESHOLD=0.6
DISABLE_RAG=false
INCLUDE_PDFS=true
OLLAMA_MODEL=llama2
CHROMA_DIR=./chroma_db
ALLOWED_ORIGINS=https://readle-sigma.vercel.app
ALLOWED_ORIGIN_REGEX=
```

## ğŸ“‹ API Endpoints

### Chat Endpoints (`/chat`)
- `POST /chat/session/new` - Create new chat session
- `POST /chat` - Send message to chatbot
- `GET /chat/session/{session_id}/history` - Get chat history
- `DELETE /chat/session/{session_id}` - Clear session
- `GET /chat/sessions/cleanup` - Clean expired sessions

### RAG Management (`/rag`)
- `POST /rag/initialize` - Initialize RAG system
- `GET /rag/status` - Get RAG system status
- `PUT /rag/threshold/{threshold}` - Update relevance threshold
- `GET /rag/test/{query}` - Test RAG relevance scoring

### System Endpoints
- `GET /` - API information
- `GET /health` - Health check
- `GET /chat/test-question-analysis/{query}` - Test question analysis

## ğŸ—ï¸ Architecture Benefits

### Modularity
- **Separation of Concerns**: Each module has a single responsibility
- **Easy Testing**: Services can be tested independently
- **Maintainable**: Changes are isolated to specific modules

### Scalability
- **Service-oriented**: Easy to extract services to microservices later
- **Configuration Management**: Centralized settings
- **Async Support**: Built for high concurrency

### Developer Experience
- **Type Safety**: Full Pydantic model validation
- **Auto Documentation**: FastAPI generates OpenAPI docs
- **Hot Reload**: Changes reflect immediately in development

## ğŸ”„ Migration from Old Structure

The old `chatbot_api.py` file is preserved for backward compatibility. To use the new structure:

1. **Start the new version**: `python run_chatbot.py`
2. **Test endpoints**: All existing endpoints work the same
3. **Verify functionality**: Chat, RAG, and health endpoints
4. **Update deployment**: Point to `chatbot.main:app` instead of `chatbot_api:app`

## ğŸ› ï¸ Development

### Adding New Features

1. **New API endpoint**: Add to appropriate router in `api/`
2. **New business logic**: Add service to `services/`
3. **New data model**: Add to `models/schemas.py`
4. **New configuration**: Add to `core/config.py`

### Testing

```bash
# Test specific service
python -c "from chatbot.services.rag import rag_service; print(rag_service.get_status())"

# Test configuration
python -c "from chatbot.core.config import settings, print_settings; print_settings()"

# Test health endpoint
curl http://localhost:8000/health
```

## ğŸ“¦ Dependencies

The restructured code uses the same dependencies as the original:
- `fastapi` - Web framework
- `uvicorn` - ASGI server
- `groq` - LLM API client
- `langchain-community` - RAG components
- `chromadb` - Vector database
- `pydantic` - Data validation
- `python-dotenv` - Environment variables

## ğŸš¢ Deployment

### Docker (recommended)
```dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY . .
RUN pip install -r requirements.txt
CMD ["python", "run_chatbot.py"]
```

### Traditional
```bash
# Install dependencies
pip install -r requirements.txt

# Run application
uvicorn chatbot.main:app --host 0.0.0.0 --port 8000
```

## ğŸ” Monitoring

The structured application provides better observability:
- Detailed startup logs with configuration
- Service-level error handling
- Health check endpoint with system status
- Structured logging throughout

## ğŸ“ˆ Performance

Benefits of the new structure:
- **Lazy Loading**: Services initialize only when needed
- **Memory Efficient**: Better resource management
- **Async Operations**: Non-blocking I/O operations
- **Caching Ready**: Easy to add caching layers

This restructured version maintains 100% API compatibility while providing a much more maintainable and scalable codebase.


ngrok http 8000